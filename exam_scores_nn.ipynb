{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Exam Scores Using a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12aa9a66130>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're defining the neural network with the following parameters:\n",
    "- **Three hidden layers** with 64, 32, 16 neurons respectively\n",
    "- We use the **LeakyReLU** activation function instead of ReLU to prevent dying neurons (from ReLU), this ensures that neurons can still learn even when they output negative values.\n",
    "- **Adam** is chosen as the optimizer because it adapts learning rates for each parameter, this leads to faster convergence and better performance on small datasets like this one without too much hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network for predicting exam scores\n",
    "class ExamScoreNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExamScoreNN, self).__init__()\n",
    "        # Define the first hidden layer\n",
    "        self.hidden1 = nn.Linear(4,64)\n",
    "        # Define the second hidden layer\n",
    "        self.hidden2 = nn.Linear(64,32)\n",
    "        # Define the third hidden layer\n",
    "        self.hidden3 = nn.Linear(32,16)\n",
    "        # Define the output layer with 1 neuron\n",
    "        self.output = nn.Linear(16,1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply ReLU activation to the hidden layer\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.relu(self.hidden3(x))\n",
    "        # Pass the result through the output layer\n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "ExamScoreNN(\n",
      "  (hidden1): Linear(in_features=4, out_features=64, bias=True)\n",
      "  (hidden2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (hidden3): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (output): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the neural network\n",
    "model = ExamScoreNN()\n",
    "\n",
    "# Print the model architecture\n",
    "print(\"Model Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: Features [Hours Studied, Hours of Sleep Before Exam, Total Attendance, Ability]\n",
    "data = torch.tensor([\n",
    "[1.0, 5.0, 80.0, 60.0],\n",
    "[2.0, 6.0, 85.0, 65.0],\n",
    "[3.0, 4.0, 90.0, 70.0],\n",
    "[4.0, 7.0, 95.0, 75.0],\n",
    "[5.0, 8.0, 100.0, 80.0],\n",
    "[2.5, 6.5, 88.0, 68.0],\n",
    "[3.5, 5.0, 92.0, 72.0],\n",
    "[1.5, 4.5, 78.0, 58.0],\n",
    "[6.0, 9.0, 110.0, 85.0],\n",
    "[4.5, 7.5, 98.0, 77.0],\n",
    "[3.0, 5.5, 87.0, 69.0],\n",
    "[2.0, 4.0, 83.0, 63.0],\n",
    "[7.0, 10.0, 120.0, 90.0],\n",
    "[5.5, 8.5, 102.0, 82.0],\n",
    "[6.5, 9.5, 115.0, 88.0],\n",
    "[4.0, 6.0, 93.0, 74.0],\n",
    "[3.5, 6.5, 89.0, 71.0],\n",
    "[1.0, 3.5, 75.0, 55.0]\n",
    "])\n",
    "# Labels: [Exam Scores]\n",
    "labels = torch.tensor([\n",
    "[50.0],\n",
    "[65.0],\n",
    "[70.0],\n",
    "[85.0],\n",
    "[90.0],\n",
    "[75.0],\n",
    "[80.0],\n",
    "[55.0],\n",
    "[95.0],\n",
    "[88.0],\n",
    "[72.0],\n",
    "[60.0],\n",
    "[100.0],\n",
    "[92.0],\n",
    "[98.0],\n",
    "[83.0],\n",
    "[78.0],\n",
    "[52.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function (Mean Squared Error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001) \n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 30.7817\n",
      "Epoch [200/1000], Loss: 23.3239\n",
      "Epoch [300/1000], Loss: 16.2880\n",
      "Epoch [400/1000], Loss: 12.0883\n",
      "Epoch [500/1000], Loss: 10.5038\n",
      "Epoch [600/1000], Loss: 9.2418\n",
      "Epoch [700/1000], Loss: 8.0996\n",
      "Epoch [800/1000], Loss: 7.2727\n",
      "Epoch [900/1000], Loss: 6.8168\n",
      "Epoch [1000/1000], Loss: 6.6733\n"
     ]
    }
   ],
   "source": [
    "# List to store loss values for visualization\n",
    "epoch_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(data)\n",
    "    loss = criterion(outputs, labels) \n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    loss.backward()        # Compute gradients\n",
    "    optimizer.step()       # Update weights\n",
    "\n",
    "    # Store the loss for this epoch\n",
    "    epoch_losses.append(loss.item())\n",
    "    \n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshopenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
